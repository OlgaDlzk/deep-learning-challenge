{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJdGQ9GdcJeW",
        "outputId": "3a01c194-5dca-45aa-f5f4-b28612cbd3bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 25)                1100      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                520       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,641\n",
            "Trainable params: 1,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5840 - accuracy: 0.7116\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5579 - accuracy: 0.7269\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5543 - accuracy: 0.7304\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5521 - accuracy: 0.7309\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5506 - accuracy: 0.7318\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7315\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5489 - accuracy: 0.7330\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7333\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7341\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5473 - accuracy: 0.7341\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5467 - accuracy: 0.7341\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5469 - accuracy: 0.7343\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7348\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7336\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5457 - accuracy: 0.7352\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7333\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5454 - accuracy: 0.7354\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7343\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7360\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7342\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7355\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7345\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5439 - accuracy: 0.7365\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7362\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5438 - accuracy: 0.7358\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7362\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7362\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7358\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7368\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7370\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5428 - accuracy: 0.7371\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5426 - accuracy: 0.7372\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7371\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5423 - accuracy: 0.7362\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7367\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7357\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7360\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7371\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7371\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7361\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7368\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7383\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5416 - accuracy: 0.7372\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5419 - accuracy: 0.7375\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7369\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7388\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7369\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7372\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7381\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7376\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7373\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5409 - accuracy: 0.7374\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5405 - accuracy: 0.7386\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7384\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7377\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7383\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7376\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7379\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7385\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.7384\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7388\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5398 - accuracy: 0.7389\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5399 - accuracy: 0.7390\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7378\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7372\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7379\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7387\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7390\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.7382\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5397 - accuracy: 0.7388\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5395 - accuracy: 0.7385\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7383\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7390\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7387\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7388\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7398\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7386\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5388 - accuracy: 0.7389\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7387\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5389 - accuracy: 0.7387\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7389\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7395\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7394\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7386\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7392\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7383\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5387 - accuracy: 0.7384\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5384 - accuracy: 0.7391\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5385 - accuracy: 0.7386\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7393\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7398\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7387\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7394\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7387\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7393\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.5381 - accuracy: 0.7399\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7392\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7398\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7396\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7401\n",
            "268/268 - 0s - loss: 0.5544 - accuracy: 0.7254 - 463ms/epoch - 2ms/step\n",
            "Loss: 0.5543779134750366, Accuracy: 0.7253644466400146\n"
          ]
        }
      ],
      "source": [
        "%run \"/content/drive/MyDrive/Colab Notebooks/Deep-learning-challenge/AlphabetSoupCharity_initialModel.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HJcFdxmqdXvE"
      },
      "outputs": [],
      "source": [
        "# Create a method that creates a new Sequential model with hyperparameter options\n",
        "def create_model(hp):\n",
        "    nn_model2 = tf.keras.models.Sequential()\n",
        "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
        "    activation = hp.Choice('activation',['sigmoid','tanh','selu'])\n",
        "    # Allow kerastuner to decide number of neurons in first layer\n",
        "    nn_model2.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "        min_value=1,\n",
        "        max_value=90,\n",
        "        step=5), activation=activation, input_dim=43))\n",
        "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
        "    for i in range(hp.Int('num_layers', 1, 6)):\n",
        "        nn_model2.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=1,\n",
        "            max_value=45,\n",
        "            step=5),\n",
        "            activation=activation))\n",
        "        \n",
        "    nn_model2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "    # Compile the model\n",
        "    nn_model2.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "    \n",
        "    return nn_model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyg3EFFkkYMK",
        "outputId": "2832d330-8d6f-4fca-ecdc-fdfefac1c6ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wuyU0pWXkNrV"
      },
      "outputs": [],
      "source": [
        "# Import the kerastuner library\n",
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=50,\n",
        "    hyperband_iterations=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUMswxwDkN17",
        "outputId": "a148062e-1c76-473e-c25d-15e80b01841b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 180 Complete [00h 02m 24s]\n",
            "val_accuracy: 0.7269970774650574\n",
            "\n",
            "Best val_accuracy So Far: 0.7303789854049683\n",
            "Total elapsed time: 01h 38m 54s\n"
          ]
        }
      ],
      "source": [
        "# Run the kerastuner search for best hyperparameters. Takes at least 1.5 hours!\n",
        "tuner.search(X_train_scaled,y_train,epochs=50,validation_data=(X_test_scaled,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2QujT3TksgI",
        "outputId": "2aa7d569-e874-4f8f-c62b-3dce8c2d9102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'activation': 'selu', 'first_units': 36, 'num_layers': 6, 'units_0': 26, 'units_1': 36, 'units_2': 41, 'units_3': 26, 'units_4': 1, 'units_5': 26, 'tuner/epochs': 50, 'tuner/initial_epoch': 17, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0081'}\n",
            "{'activation': 'selu', 'first_units': 36, 'num_layers': 6, 'units_0': 26, 'units_1': 36, 'units_2': 41, 'units_3': 26, 'units_4': 1, 'units_5': 26, 'tuner/epochs': 17, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
            "{'activation': 'tanh', 'first_units': 11, 'num_layers': 4, 'units_0': 36, 'units_1': 36, 'units_2': 26, 'units_3': 11, 'units_4': 1, 'units_5': 11, 'tuner/epochs': 50, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
          ]
        }
      ],
      "source": [
        "# Get top 3 model hyperparameters and print the values\n",
        "top_hyper = tuner.get_best_hyperparameters(3)\n",
        "for param in top_hyper:\n",
        "    print(param.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix7qIQEbksv5",
        "outputId": "b21f1853-b9e0-4e61-dd88-aaf7a3c79b45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 1s - loss: 0.5499 - accuracy: 0.7304 - 1s/epoch - 4ms/step\n",
            "Loss: 0.5499333143234253, Accuracy: 0.7303789854049683\n",
            "268/268 - 1s - loss: 0.5544 - accuracy: 0.7301 - 641ms/epoch - 2ms/step\n",
            "Loss: 0.5543621778488159, Accuracy: 0.7301457524299622\n",
            "268/268 - 1s - loss: 0.5505 - accuracy: 0.7294 - 676ms/epoch - 3ms/step\n",
            "Loss: 0.5504990816116333, Accuracy: 0.7294460535049438\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the top 3 models against the test dataset\n",
        "top_model = tuner.get_best_models(3)\n",
        "for model in top_model:\n",
        "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1sa9Sc0lAHX",
        "outputId": "187e5dd2-ed4c-4974-9f51-9b10e391bbaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'selu',\n",
              " 'first_units': 36,\n",
              " 'num_layers': 6,\n",
              " 'units_0': 26,\n",
              " 'units_1': 36,\n",
              " 'units_2': 41,\n",
              " 'units_3': 26,\n",
              " 'units_4': 1,\n",
              " 'units_5': 26,\n",
              " 'tuner/epochs': 50,\n",
              " 'tuner/initial_epoch': 17,\n",
              " 'tuner/bracket': 1,\n",
              " 'tuner/round': 1,\n",
              " 'tuner/trial_id': '0081'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the best model hyperparameters\n",
        "first_hyper = tuner.get_best_hyperparameters(1)[0]\n",
        "first_hyper.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cEHp5TpWtGz4"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "tf.keras.models.save_model(nn_model, 'AlphabetSoupCharity_SECONDoptimization_HP.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
